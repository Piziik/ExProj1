{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported v0.1.905. Please call AutoViz in this sequence:\n",
      "    AV = AutoViz_Class()\n",
      "    %matplotlib inline\n",
      "    dfte = AV.AutoViz(filename, sep=',', depVar='', dfte=None, header=0, verbose=1, lowess=False,\n",
      "               chart_format='svg',max_rows_analyzed=150000,max_cols_analyzed=30, save_plot_dir=None)\n",
      "Shape of your Data Set loaded: (37715, 10)\n",
      "#######################################################################################\n",
      "######################## C L A S S I F Y I N G  V A R I A B L E S  ####################\n",
      "#######################################################################################\n",
      "Classifying variables in data set...\n",
      "    Number of Numeric Columns =  5\n",
      "    Number of Integer-Categorical Columns =  0\n",
      "    Number of String-Categorical Columns =  1\n",
      "    Number of Factor-Categorical Columns =  0\n",
      "    Number of String-Boolean Columns =  0\n",
      "    Number of Numeric-Boolean Columns =  0\n",
      "    Number of Discrete String Columns =  0\n",
      "    Number of NLP String Columns =  4\n",
      "    Number of Date Time Columns =  0\n",
      "    Number of ID Columns =  0\n",
      "    Number of Columns to Delete =  0\n",
      "    10 Predictors classified...\n",
      "        No variables removed since no ID or low-information variables found in data set\n",
      "To fix these data quality issues in the dataset, import FixDQ from autoviz...\n",
      "    All variables classified into correct types.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_10405_row0_col0, #T_10405_row0_col2, #T_10405_row0_col3, #T_10405_row0_col4, #T_10405_row0_col5, #T_10405_row1_col0, #T_10405_row1_col2, #T_10405_row1_col3, #T_10405_row1_col4, #T_10405_row1_col5, #T_10405_row2_col0, #T_10405_row2_col2, #T_10405_row2_col3, #T_10405_row2_col4, #T_10405_row2_col5, #T_10405_row3_col0, #T_10405_row3_col2, #T_10405_row3_col3, #T_10405_row3_col4, #T_10405_row3_col5, #T_10405_row4_col0, #T_10405_row4_col2, #T_10405_row4_col3, #T_10405_row4_col4, #T_10405_row4_col5, #T_10405_row5_col0, #T_10405_row5_col2, #T_10405_row5_col3, #T_10405_row5_col4, #T_10405_row5_col5, #T_10405_row6_col0, #T_10405_row6_col2, #T_10405_row6_col3, #T_10405_row6_col4, #T_10405_row6_col5, #T_10405_row7_col0, #T_10405_row7_col2, #T_10405_row7_col3, #T_10405_row7_col4, #T_10405_row7_col5, #T_10405_row8_col0, #T_10405_row8_col2, #T_10405_row8_col3, #T_10405_row8_col4, #T_10405_row8_col5, #T_10405_row9_col0, #T_10405_row9_col2, #T_10405_row9_col3, #T_10405_row9_col4, #T_10405_row9_col5 {\n",
       "  font-family: Segoe UI;\n",
       "}\n",
       "#T_10405_row0_col1, #T_10405_row1_col1, #T_10405_row2_col1, #T_10405_row3_col1, #T_10405_row4_col1, #T_10405_row5_col1, #T_10405_row6_col1, #T_10405_row7_col1, #T_10405_row8_col1, #T_10405_row9_col1 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "  font-family: Segoe UI;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_10405\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_10405_level0_col0\" class=\"col_heading level0 col0\" >Data Type</th>\n",
       "      <th id=\"T_10405_level0_col1\" class=\"col_heading level0 col1\" >Missing Values%</th>\n",
       "      <th id=\"T_10405_level0_col2\" class=\"col_heading level0 col2\" >Unique Values%</th>\n",
       "      <th id=\"T_10405_level0_col3\" class=\"col_heading level0 col3\" >Minimum Value</th>\n",
       "      <th id=\"T_10405_level0_col4\" class=\"col_heading level0 col4\" >Maximum Value</th>\n",
       "      <th id=\"T_10405_level0_col5\" class=\"col_heading level0 col5\" >DQ Issue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_10405_level0_row0\" class=\"row_heading level0 row0\" >name</th>\n",
       "      <td id=\"T_10405_row0_col0\" class=\"data row0 col0\" >object</td>\n",
       "      <td id=\"T_10405_row0_col1\" class=\"data row0 col1\" >0.000000</td>\n",
       "      <td id=\"T_10405_row0_col2\" class=\"data row0 col2\" >96</td>\n",
       "      <td id=\"T_10405_row0_col3\" class=\"data row0 col3\" ></td>\n",
       "      <td id=\"T_10405_row0_col4\" class=\"data row0 col4\" ></td>\n",
       "      <td id=\"T_10405_row0_col5\" class=\"data row0 col5\" >No issue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_10405_level0_row1\" class=\"row_heading level0 row1\" >publisher</th>\n",
       "      <td id=\"T_10405_row1_col0\" class=\"data row1 col0\" >object</td>\n",
       "      <td id=\"T_10405_row1_col1\" class=\"data row1 col1\" >0.000000</td>\n",
       "      <td id=\"T_10405_row1_col2\" class=\"data row1 col2\" >8</td>\n",
       "      <td id=\"T_10405_row1_col3\" class=\"data row1 col3\" ></td>\n",
       "      <td id=\"T_10405_row1_col4\" class=\"data row1 col4\" ></td>\n",
       "      <td id=\"T_10405_row1_col5\" class=\"data row1 col5\" >No issue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_10405_level0_row2\" class=\"row_heading level0 row2\" >vgchartz_score</th>\n",
       "      <td id=\"T_10405_row2_col0\" class=\"data row2 col0\" >float64</td>\n",
       "      <td id=\"T_10405_row2_col1\" class=\"data row2 col1\" >0.000000</td>\n",
       "      <td id=\"T_10405_row2_col2\" class=\"data row2 col2\" >NA</td>\n",
       "      <td id=\"T_10405_row2_col3\" class=\"data row2 col3\" >1.100000</td>\n",
       "      <td id=\"T_10405_row2_col4\" class=\"data row2 col4\" >9.700000</td>\n",
       "      <td id=\"T_10405_row2_col5\" class=\"data row2 col5\" >Column has 1565 outliers greater than upper bound (7.31) or lower than lower bound(7.31). Cap them or remove them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_10405_level0_row3\" class=\"row_heading level0 row3\" >critic_score</th>\n",
       "      <td id=\"T_10405_row3_col0\" class=\"data row3 col0\" >float64</td>\n",
       "      <td id=\"T_10405_row3_col1\" class=\"data row3 col1\" >0.000000</td>\n",
       "      <td id=\"T_10405_row3_col2\" class=\"data row3 col2\" >NA</td>\n",
       "      <td id=\"T_10405_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "      <td id=\"T_10405_row3_col4\" class=\"data row3 col4\" >10.000000</td>\n",
       "      <td id=\"T_10405_row3_col5\" class=\"data row3 col5\" >Column has 3969 outliers greater than upper bound (7.23) or lower than lower bound(7.23). Cap them or remove them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_10405_level0_row4\" class=\"row_heading level0 row4\" >user_score</th>\n",
       "      <td id=\"T_10405_row4_col0\" class=\"data row4 col0\" >float64</td>\n",
       "      <td id=\"T_10405_row4_col1\" class=\"data row4 col1\" >0.000000</td>\n",
       "      <td id=\"T_10405_row4_col2\" class=\"data row4 col2\" >NA</td>\n",
       "      <td id=\"T_10405_row4_col3\" class=\"data row4 col3\" >1.000000</td>\n",
       "      <td id=\"T_10405_row4_col4\" class=\"data row4 col4\" >10.000000</td>\n",
       "      <td id=\"T_10405_row4_col5\" class=\"data row4 col5\" >Column has 269 outliers greater than upper bound (8.09) or lower than lower bound(8.09). Cap them or remove them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_10405_level0_row5\" class=\"row_heading level0 row5\" >total_shipped</th>\n",
       "      <td id=\"T_10405_row5_col0\" class=\"data row5 col0\" >float64</td>\n",
       "      <td id=\"T_10405_row5_col1\" class=\"data row5 col1\" >0.000000</td>\n",
       "      <td id=\"T_10405_row5_col2\" class=\"data row5 col2\" >NA</td>\n",
       "      <td id=\"T_10405_row5_col3\" class=\"data row5 col3\" >0.000000</td>\n",
       "      <td id=\"T_10405_row5_col4\" class=\"data row5 col4\" >496.400000</td>\n",
       "      <td id=\"T_10405_row5_col5\" class=\"data row5 col5\" >Column has 2873 outliers greater than upper bound (5.07) or lower than lower bound(5.07). Cap them or remove them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_10405_level0_row6\" class=\"row_heading level0 row6\" >total_sales</th>\n",
       "      <td id=\"T_10405_row6_col0\" class=\"data row6 col0\" >float64</td>\n",
       "      <td id=\"T_10405_row6_col1\" class=\"data row6 col1\" >0.000000</td>\n",
       "      <td id=\"T_10405_row6_col2\" class=\"data row6 col2\" >NA</td>\n",
       "      <td id=\"T_10405_row6_col3\" class=\"data row6 col3\" >0.000000</td>\n",
       "      <td id=\"T_10405_row6_col4\" class=\"data row6 col4\" >20.320000</td>\n",
       "      <td id=\"T_10405_row6_col5\" class=\"data row6 col5\" >Column has 11961 outliers greater than upper bound (0.37) or lower than lower bound(0.29). Cap them or remove them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_10405_level0_row7\" class=\"row_heading level0 row7\" >release_date</th>\n",
       "      <td id=\"T_10405_row7_col0\" class=\"data row7 col0\" >object</td>\n",
       "      <td id=\"T_10405_row7_col1\" class=\"data row7 col1\" >0.000000</td>\n",
       "      <td id=\"T_10405_row7_col2\" class=\"data row7 col2\" >19</td>\n",
       "      <td id=\"T_10405_row7_col3\" class=\"data row7 col3\" ></td>\n",
       "      <td id=\"T_10405_row7_col4\" class=\"data row7 col4\" ></td>\n",
       "      <td id=\"T_10405_row7_col5\" class=\"data row7 col5\" >No issue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_10405_level0_row8\" class=\"row_heading level0 row8\" >genre</th>\n",
       "      <td id=\"T_10405_row8_col0\" class=\"data row8 col0\" >object</td>\n",
       "      <td id=\"T_10405_row8_col1\" class=\"data row8 col1\" >0.000000</td>\n",
       "      <td id=\"T_10405_row8_col2\" class=\"data row8 col2\" >0</td>\n",
       "      <td id=\"T_10405_row8_col3\" class=\"data row8 col3\" ></td>\n",
       "      <td id=\"T_10405_row8_col4\" class=\"data row8 col4\" ></td>\n",
       "      <td id=\"T_10405_row8_col5\" class=\"data row8 col5\" >7 rare categories: ['Visual Novel', 'Music', 'Party', 'MMO', 'Board Game', 'Education', 'Sandbox']. Group them into a single category or drop the categories.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_10405_level0_row9\" class=\"row_heading level0 row9\" >img_url</th>\n",
       "      <td id=\"T_10405_row9_col0\" class=\"data row9 col0\" >object</td>\n",
       "      <td id=\"T_10405_row9_col1\" class=\"data row9 col1\" >0.000000</td>\n",
       "      <td id=\"T_10405_row9_col2\" class=\"data row9 col2\" >90</td>\n",
       "      <td id=\"T_10405_row9_col3\" class=\"data row9 col3\" ></td>\n",
       "      <td id=\"T_10405_row9_col4\" class=\"data row9 col4\" ></td>\n",
       "      <td id=\"T_10405_row9_col5\" class=\"data row9 col5\" >No issue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1e6cdeb8880>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of All Scatter Plots = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\gabyd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\gabyd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\gabyd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\gabyd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\gabyd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\gabyd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\gabyd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\gabyd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\gabyd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\gabyd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\gabyd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\gabyd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\gabyd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\gabyd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\gabyd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\gabyd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\gabyd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\gabyd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\gabyd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\gabyd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\gabyd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\gabyd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not draw wordcloud plot for name. \n",
      "Looks like you are missing some required data for this feature.\n",
      "\n",
      "To download the necessary data, simply run\n",
      "\n",
      "    python -m textblob.download_corpora\n",
      "\n",
      "or use the NLTK downloader to download the missing data: http://nltk.org/data.html\n",
      "If this doesn't fix the problem, file an issue at https://github.com/sloria/TextBlob/issues.\n",
      "\n",
      "Could not draw wordcloud plot for img_url. \n",
      "Looks like you are missing some required data for this feature.\n",
      "\n",
      "To download the necessary data, simply run\n",
      "\n",
      "    python -m textblob.download_corpora\n",
      "\n",
      "or use the NLTK downloader to download the missing data: http://nltk.org/data.html\n",
      "If this doesn't fix the problem, file an issue at https://github.com/sloria/TextBlob/issues.\n",
      "\n",
      "Could not draw wordcloud plot for publisher. \n",
      "Looks like you are missing some required data for this feature.\n",
      "\n",
      "To download the necessary data, simply run\n",
      "\n",
      "    python -m textblob.download_corpora\n",
      "\n",
      "or use the NLTK downloader to download the missing data: http://nltk.org/data.html\n",
      "If this doesn't fix the problem, file an issue at https://github.com/sloria/TextBlob/issues.\n",
      "\n",
      "Could not draw wordcloud plot for release_date. \n",
      "Looks like you are missing some required data for this feature.\n",
      "\n",
      "To download the necessary data, simply run\n",
      "\n",
      "    python -m textblob.download_corpora\n",
      "\n",
      "or use the NLTK downloader to download the missing data: http://nltk.org/data.html\n",
      "If this doesn't fix the problem, file an issue at https://github.com/sloria/TextBlob/issues.\n",
      "\n",
      "All Plots done\n",
      "Time to run AutoViz = 14 seconds \n",
      "\n",
      " ###################### AUTO VISUALIZATION Completed ########################\n"
     ]
    }
   ],
   "source": [
    "from autoviz.AutoViz_Class import AutoViz_Class\n",
    "AV = AutoViz_Class()\n",
    "report = AV.AutoViz(\"../Model/VGChartzGamesSalesDataset.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
